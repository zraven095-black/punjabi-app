import streamlit as st
import pandas as pd
import emoji
import re
from collections import Counter

# --- Configuration & Styles ---
st.set_page_config(
    page_title="Lafz-Vigyan",
    page_icon="üìù",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Custom CSS for Dark Mode aesthetics
st.markdown("""
    <style>
    .stApp {
        background-color: #0E1117;
        color: #FAFAFA;
    }
    .metric-card {
        background-color: #262730;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    h1, h2, h3 {
        font-family: 'Inter', sans-serif;
    }
    .stTextArea textarea {
        background-color: #262730;
        color: #FAFAFA;
        border: 1px solid #4B5563;
    }
    </style>
    """, unsafe_allow_html=True)

# --- Standard Dictionary (Sample of 100+ common Punjabi words) ---
# This serves as the baseline for "Known Words". In a real app, this would be a database.
STANDARD_PUNJABI_DICT = set([
    "‡®Æ‡©à‡®Ç", "‡®§‡©Ç‡©∞", "‡®Ö‡®∏‡©Ä‡®Ç", "‡®§‡©Å‡®∏‡©Ä‡®Ç", "‡®â‡®π", "‡®π‡®æ‡®Ç", "‡®∏‡©Ä", "‡®®‡©á", "‡®®‡©Ç‡©∞", "‡®¶‡®æ", "‡®¶‡©á", "‡®¶‡©Ä", "‡®µ‡®ø‡©±‡®ö", "‡®§‡©á", "‡®Ö‡®§‡©á",
    "‡®™‡®∞", "‡®ú‡®æ‡®Ç", "‡®ï‡®ø‡®â‡®Ç‡®ï‡®ø", "‡®ú‡®¶‡©ã‡®Ç", "‡®§‡®¶", "‡®π‡©Å‡®£", "‡®ï‡©±‡®≤‡©ç‡®π", "‡®Ö‡©±‡®ú", "‡®∏‡®æ‡®°‡®æ", "‡®§‡©Å‡®π‡®æ‡®°‡®æ", "‡®Æ‡©á‡®∞‡®æ", "‡®ï‡©Ä", "‡®ï‡®ø‡®µ‡©á‡®Ç",
    "‡®ï‡®ø‡©±‡®•‡©á", "‡®ï‡©å‡®£", "‡®ú‡®æ", "‡®Ü", "‡®ñ‡®æ", "‡®™‡©Ä", "‡®∏‡©å‡®Ç", "‡®∞‡®π‡®ø", "‡®ï‡®∞", "‡®¶‡©á‡®ñ", "‡®∏‡©Å‡®£", "‡®¨‡©ã‡®≤", "‡®≤‡®ø‡®ñ", "‡®™‡©ú‡©ç‡®π",
    "‡®ò‡®∞", "‡®∏‡®ï‡©Ç‡®≤", "‡®ï‡©∞‡®Æ", "‡®™‡®æ‡®£‡©Ä", "‡®∞‡©ã‡®ü‡©Ä", "‡®ö‡®æ‡®π", "‡®¶‡©Å‡©±‡®ß", "‡®Æ‡®æ‡®Ç", "‡®™‡®ø‡®ì", "‡®≠‡®∞‡®æ", "‡®≠‡©à‡®£", "‡®¶‡©ã‡®∏‡®§", "‡®Æ‡®ø‡©±‡®§‡®∞",
    "‡®ñ‡©Å‡®∏‡®º‡©Ä", "‡®ó‡®º‡®Æ", "‡®™‡®ø‡®Ü‡®∞", "‡®®‡®´‡®º‡®∞‡®§", "‡®ú‡®º‡®ø‡©∞‡®¶‡®ó‡©Ä", "‡®Æ‡©å‡®§", "‡®∏‡©±‡®ö", "‡®ù‡©Ç‡®†", "‡®¶‡®ø‡®®", "‡®∞‡®æ‡®§", "‡®∏‡®µ‡©á‡®∞", "‡®∏‡®º‡®æ‡®Æ",
    "‡®µ‡®ß‡©Ä‡®Ü", "‡®Æ‡®æ‡©ú‡®æ", "‡®ö‡©∞‡®ó‡®æ", "‡®∏‡©ã‡®π‡®£‡®æ", "‡®µ‡©±‡®°‡®æ", "‡®õ‡©ã‡®ü‡®æ", "‡®®‡®µ‡®æ‡®Ç", "‡®™‡©Å‡®∞‡®æ‡®£‡®æ", "‡®≤‡®æ‡®≤", "‡®ï‡®æ‡®≤‡®æ", "‡®ö‡®ø‡©±‡®ü‡®æ", "‡®®‡©Ä‡®≤‡®æ",
    "‡®á‡©±‡®ï", "‡®¶‡©ã", "‡®§‡®ø‡©∞‡®®", "‡®ö‡®æ‡®∞", "‡®™‡©∞‡®ú", "‡®¶‡®∏", "‡®∏‡©å", "‡®π‡®ú‡®º‡®æ‡®∞", "‡®≤‡©±‡®ñ", "‡®ï‡®∞‡©ã‡©ú",
    "‡®≠‡®æ‡®∞‡®§", "‡®™‡©∞‡®ú‡®æ‡®¨", "‡®¶‡©Å‡®®‡©Ä‡®Ü", "‡®ß‡®∞‡®§‡©Ä", "‡®Ö‡®∏‡®Æ‡®æ‡®®", "‡®∏‡©Ç‡®∞‡®ú", "‡®ö‡©∞‡®¶", "‡®§‡®æ‡®∞‡©á", "‡®π‡®µ‡®æ", "‡®Ö‡©±‡®ó",
    "‡®ï‡®ø‡®§‡®æ‡®¨", "‡®ï‡®æ‡®™‡©Ä", "‡®ï‡®≤‡®Æ", "‡®´‡©ã‡®®", "‡®ó‡©±‡®°‡©Ä", "‡®¨‡©±‡®∏", "‡®∞‡©á‡®≤", "‡®ú‡®π‡®æ‡®ú‡®º", "‡®∞‡®∏‡®§‡®æ", "‡®∏‡®º‡®π‡®ø‡®∞", "‡®™‡®ø‡©∞‡®°"
])

# --- Helper Functions ---

def clean_text_gurmukhi(text):
    """
    Tokenizes text by removing punctuation and numbers, keeping Gurmukhi chars.
    """
    # Remove emojis and generic punctuation for word analysis
    text_no_emoji = emoji.replace_emoji(text, replace='')
    # Keep Gurmukhi characters and basic punctuation marks potentially part of words if needed,
    # but strictly speaking we want to isolate words.
    # Pattern: Blocks not suitable for Gurmukhi words (keep \w which includes Unicode letters)
    # Simple regex to extract sequences of alphanumeric chars (Unicode aware)
    words = re.findall(r'\w+', text_no_emoji)
    return [w for w in words if not w.isnumeric()] 

def extract_emojis(text):
    """
    Returns a list of all emojis found in the text.
    """
    return [char['emoji'] for char in emoji.emoji_list(text)]

def calculate_evolution_score(neologism_count, total_words):
    if total_words == 0:
        return 0
    return (neologism_count / total_words) * 100

# --- Main Application ---

def main():
    st.title("Lafz-Vigyan: Punjabi Digital Evolution Tracker")
    st.markdown("### Detect new Punjabi words and track digital language trends.")

    # Sidebar for Context & Disclaimer
    with st.sidebar:
        st.header("About")
        st.info(
            "**Academic Disclaimer**:\n\n"
            "This tool uses simulated data for conceptual research demonstration. "
            "It compares input text against a limited prototype lexicon."
        )
        st.markdown("---")
        st.markdown("**Version**: 1.0.0 (Research Prototype)")

    # Input Section
    with st.container():
        user_input = st.text_area("Paste Punjabi Text Here:", height=200, placeholder="‡®∏‡®§‡®ø ‡®∏‡®º‡©ç‡®∞‡©Ä ‡®Ö‡®ï‡®æ‡®≤! ‡®Ö‡©±‡®ú ‡®ï‡©±‡®≤‡©ç‡®π ‡®∏‡©ã‡®∏‡®º‡®≤ ‡®Æ‡©Ä‡®°‡©Ä‡®Ü '‡®§‡©á ‡®¨‡®π‡©Å‡®§ hashtag ‡®ö‡©±‡®≤ ‡®∞‡®π‡©á ‡®π‡®®...")

    if st.button("Analyze Text", type="primary"):
        if not user_input.strip():
            st.warning("Please enter some text to analyze.")
            return

        with st.spinner("Analyzing linguistic patterns..."):
            # 1. Extraction & Cleaning
            all_words_raw = clean_text_gurmukhi(user_input)
            all_emojis = extract_emojis(user_input)
            
            # Filter empty strings if any
            all_words = [w for w in all_words_raw if w.strip()]
            total_word_count = len(all_words)
            
            # 2. Neologism Detection
            # Normalize dictionary for comparison? (Assuming dict provided is standard)
            known_words_set = STANDARD_PUNJABI_DICT
            
            neologisms = []
            known_count = 0
            
            for word in all_words:
                if word in known_words_set:
                    known_count += 1
                else:
                    neologisms.append(word)
            
            neologism_counts = Counter(neologisms)
            emoji_counts = Counter(all_emojis)
            
            neologism_total_count = len(neologisms)
            evolution_score = calculate_evolution_score(neologism_total_count, total_word_count)

            # 3. Display Metrics
            st.markdown("### Analysis Results")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Words", total_word_count)
            with col2:
                st.metric("Neologisms Found", neologism_total_count, delta=f"{evolution_score:.1f}% Ratio", delta_color="inverse")
            with col3:
                st.metric("Emojis Used", len(all_emojis))
            with col4:
                st.metric("Known Words", known_count)

            st.divider()

            # 4. Detailed Breakdown
            row1_col1, row1_col2 = st.columns([1, 1])

            with row1_col1:
                st.subheader("Potential New Words")
                if neologism_counts:
                    neo_df = pd.DataFrame(neologism_counts.items(), columns=["Word", "Frequency"]).sort_values(by="Frequency", ascending=False)
                    st.dataframe(neo_df, use_container_width=True, hide_index=True)
                    
                    # Download CSV
                    csv = neo_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="üìÑ Download Neologism Report",
                        data=csv,
                        file_name="punjabi_neologisms.csv",
                        mime="text/csv",
                    )
                else:
                    st.info("No new words detected based on the current standard dictionary.")

            with row1_col2:
                st.subheader("Top Used Emojis")
                if emoji_counts:
                    emoji_df = pd.DataFrame(emoji_counts.most_common(5), columns=["Emoji", "Count"])
                    # Use st.bar_chart
                    st.bar_chart(emoji_df.set_index("Emoji"))
                else:
                    st.caption("No emojis found in the text.")

            # 5. Language Evolution Score Visual
            st.subheader("Language Evolution Score")
            st.progress(min(evolution_score / 100, 1.0))
            if evolution_score > 50:
                 st.caption(f"‚ö†Ô∏è High divergence ({evolution_score:.1f}%) from standard lexicon.")
            else:
                 st.caption(f"This text diverges {evolution_score:.1f}% from the standard lexicon.")

if __name__ == "__main__":
    main()
